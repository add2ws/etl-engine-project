# Etl-engine

**ä¸­æ–‡** | [English](README.en.md)

## ğŸš€ ç®€ä»‹ï¼šé«˜æ€§èƒ½ ETL å¼•æ“

**`Etl-engine`** æ˜¯ä¸€ä¸ªè½»é‡ã€ç¨³å¥ã€æ˜“æ‰©å±•çš„é¢å‘å¼€å‘è€…çš„ ETLï¼ˆæŠ½å–ã€è½¬æ¢ã€åŠ è½½ï¼‰åº“ï¼Œæ—¨åœ¨æˆä¸º **Kettle (PDI) çš„é«˜æ€§èƒ½æ›¿ä»£æ–¹æ¡ˆã€‚

-----

## ğŸ”¥ æ ¸å¿ƒä¼˜åŠ¿

**`Etl-engine`** æä¾›ä»¥ä¸‹ä¸‰å¤§æ ¸å¿ƒç‰¹æ€§ï¼š

### 1. æè‡´çš„é€Ÿåº¦ âš¡ï¸

é€šè¿‡æ‰¹é‡æ“ä½œå’Œéé˜»å¡çš„ç¼“å­˜ç®¡é“è®¾è®¡ï¼Œæ˜¾è‘—æå‡æ•°æ®å¤„ç†å’Œæ•°æ®åº“ I/O é€Ÿåº¦ã€‚

ğŸ“Š **å®æµ‹æ•°æ®ï¼š** å¤„ç† $200,000$ æ¡æ•°æ®çš„æ’å…¥/æ›´æ–°ä»»åŠ¡ï¼Œ`etl-engine` çš„é€Ÿåº¦æ˜¯ **Kettle çš„ $\mathbf{2}$ å€å·¦å³**ã€‚

**Kettle:**
![1765353174408](image/README.cn/1765353174408.png)

**Etl-engine:**
![1765353763090](image/README.cn/1765353763090.png)

### 2. è¿è¡Œç¨³å¥å¯é  ğŸ›¡ï¸

æ•°æ®æµä¼ è¾“è¿‡ç¨‹ä¸­å¦‚æœé‡åˆ°å¼‚å¸¸ä¸ä¼šé©¬ä¸Šåœæ­¢ï¼Œè‡ªåŠ¨å°è¯•é‡æ–°è¯»å–æˆ–å†™å…¥æ•°æ®ã€‚

### 3. è½»é‡ä¸”æ˜“äºæ‰©å±• ğŸ§©

æ ¸å¿ƒä»…ç”± **Node(èŠ‚ç‚¹)** , **Pipe(ç®¡é“)** , **Dataflow(æ•°æ®æµ)** 3ä¸ªä¸»è¦ç»„ä»¶æ„æˆï¼Œæ‰€æœ‰æ•°æ®åŠ è½½é€»è¾‘éƒ½æŠ½è±¡ä¸ºå¯æ‰©å±•çš„**èŠ‚ç‚¹**ã€‚é™¤äº†å†…ç½®çš„JDBCæ•°æ®æºèŠ‚ç‚¹ï¼Œç”¨æˆ·å¯ä»¥è½»æ¾ç»§æ‰¿åŸºç±»ï¼Œå¿«é€Ÿå¼€å‘æ–°çš„æ•°æ®æºï¼ˆå¦‚ Httpã€Redisï¼‰æˆ–è‡ªå®šä¹‰è½¬æ¢é€»è¾‘ï¼Œæ»¡è¶³ç‰¹å®šçš„ä¸šåŠ¡éœ€æ±‚ã€‚

-----

## ğŸ› ï¸ ä½¿ç”¨ç¤ºä¾‹

ä»¥ä¸‹ä»£ç å±•ç¤ºäº†å¦‚ä½•å¿«é€Ÿæ„å»ºä¸€ä¸ªå°† **Oracle æ•°æ®ï¼ˆæŠ½å–ï¼‰** é€šè¿‡ **Upsert æ–¹å¼åŒæ­¥åˆ° PostgreSQLï¼ˆåŠ è½½ï¼‰** çš„ ETL ä»»åŠ¡ã€‚

### 1. ä¸€ä¸ªè¡¨è¾“å…¥åˆ°ä¸€ä¸ªè¡¨è¾“å‡º

```mermaid
flowchart LR
  sqlInputNode --pipe--> upsertOutputNode
```

```java

//åˆ›å»ºOracleæ•°æ®æº
DataSource dataSourceOracle = DataSourceUtil.getOracleDataSource();
//åˆ›å»ºè¡¨è¾“å…¥èŠ‚ç‚¹
SqlInputNode sqlInputNode = new SqlInputNode(dataSourceOracle, "select * from t_resident_info");

//åˆ›å»ºPostgresæ•°æ®æº
DataSource dataSourcePG = DataSourceUtil.getPostgresDataSource();
//åˆ›å»ºæ’å…¥/æ›´æ–°èŠ‚ç‚¹
UpsertOutputNode upsertOutputNode = new UpsertOutputNode(dataSourcePG, "t_resident_info", 1000);
//è®¾ç½®å”¯ä¸€æ ‡è¯†(ä¸»é”®)æ˜ å°„ï¼Œç”¨äºåˆ¤æ–­ Insert æˆ– Update
upsertOutputNode.setIdentityMapping(Arrays.asList(new Tuple2<>("ID", "ID")));

//åˆ›å»ºç®¡é“ï¼Œå¹¶è®¾å®šç¼“å†²åŒºä¸º1000æ¡æ•°æ®
Pipe pipe = new Pipe(1000);
//è¿æ¥è¡¨è¾“å…¥å’Œè¾“å‡ºèŠ‚ç‚¹
pipe.connect(sqlInputNode, upsertOutputNode);

//åˆ›å»ºæ•°æ®æµå®ä¾‹
Dataflow dataflow = new Dataflow(sqlInputNode);
//å¯åŠ¨æ•°æ®æµï¼Œå¹¶è®¾å®š5åˆ†é’Ÿåè¶…æ—¶
dataflow.syncStart(5, TimeUnit.MINUTES);
```

### 2. ä¸€ä¸ªè¡¨è¾“å…¥ç»è¿‡å­—æ®µå€¼è½¬æ¢åˆ°ä¸€ä¸ªè¡¨è¾“å‡º

```mermaid
flowchart LR
  sqlInputNode --pipe-->valueConverter --pipe--> upsertOutputNode
```

```java
//todo
```

### 3. ä¸€ä¸ªè¡¨è¾“å…¥åˆ°å¤šä¸ªè¾“å‡º

```mermaid
flowchart LR
  sqlInputNode --pipe--> upsertOutputNode
  sqlInputNode --pipe--> csvOutputNode
```

```java
//åˆ›å»ºOracleæ•°æ®æº
DataSource oracleDataSource = DataSourceUtil.getOracleDataSource();
SqlInputNode sqlInputNode = new SqlInputNode(oracleDataSource, "select * from etl_base.t_resident_info where rownum<=50000 order by id");

//åˆ›å»ºPostgresç›®æ ‡æ•°æ®æº
DataSource postgresDataSource = DataSourceUtil.getPostgresDataSource();
UpsertOutputNode upsertOutputNode = new UpsertOutputNode(postgresDataSource, "public.t_resident_info", 1000);
upsertOutputNode.setIdentityMapping(Arrays.asList(new Tuple2<>("ID","ID")));

//åˆ›å»ºcsvæ–‡ä»¶ç›®æ ‡
FileOutputNode fileOutputNode = new FileOutputNode("E:/output_" + System.currentTimeMillis() + ".csv", FileOutputNode.Format.CSV);

//åˆ›å»ºç®¡é“å¹¶è¿æ¥Oracleå’ŒPostgres
Pipe pipe = new Pipe(1000);
pipe.connect(sqlInputNode,upsertOutputNode);

//åˆ›å»ºç®¡é“å¹¶è¿æ¥Oracleå’Œcsvæ–‡ä»¶
Pipe pipe_2 = new Pipe(1000);
pipe_2.connect(sqlInputNode,fileOutputNode);

//åˆ›å»ºæ•°æ®æµå¹¶å¯åŠ¨
Dataflow dataflow = new Dataflow(sqlInputNode);
dataflow.syncStart();

```

-----

## ğŸ—ï¸ æ¶æ„æ¦‚è§ˆ

`Etl-engine` æ ¸å¿ƒä»…ç”±ä»¥ä¸‹3ä¸ªä¸»è¦ç»„ä»¶æ„æˆï¼š

* **Node (èŠ‚ç‚¹):** æ•°æ®çš„èµ·ç‚¹ã€ç»ˆç‚¹å’Œæ•°æ®è½¬æ¢é€»è¾‘è½½ä½“ã€‚
* **Pipe (ç®¡é“):** è´Ÿè´£åœ¨èŠ‚ç‚¹é—´ä¼ é€’æ•°æ®çš„éé˜»å¡ç¼“å­˜é˜Ÿåˆ—ã€‚
* **Dataflow (æ•°æ®æµ):** ä»»åŠ¡çš„ç¼–æ’å™¨å’Œæ‰§è¡Œå…¥å£ã€‚
